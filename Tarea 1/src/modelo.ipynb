{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de entrenamiento para la base de datos golf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías\n",
    "\n",
    "Importamos las librerías pandas y numpy para agilizar el manejo de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### traform_data(df)\n",
    "\n",
    "Esta función es la encargada de transformar el `DataFrame` *`df`*. La transformación consiste en reemplazar la columna `outlook`, que contiene los valores ***sunny***, ***rainy***, y ***outcast***, por tres nuevas columnas con los mismos nombres. Los valores de estas columnas son un $1$ o un $0$, dependiendo del antiguo valor de `outlook`.  \n",
    "\n",
    "> **NOTA:** La transformación de la base de datos ha sido programada específicamente para la base de datos `golf` y cualquier otra base de datos con la misma estructura.  \n",
    "> En caso de introducir una base de datos que no cumpla esta condición, el programa no arrojará los resultados esperados.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    dummies       = pd.get_dummies(df['outlook'])\n",
    "    df            = pd.concat([df, dummies], axis=1)\n",
    "    df            = df.drop(['outlook'], axis=1)\n",
    "    cols          = df.columns.tolist()\n",
    "    cols          = cols[-1 : -4 : -1] + cols[:-3]\n",
    "    df[cols[:-1]] = df[cols[:-1]].astype(np.int64)\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read_data(path)\n",
    "\n",
    "Una simple función que lee una base de datos de un archivo csv desde el `path` a un `DataFrame`, y retorna la transformación de este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return transform_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split_data(df, train_size)\n",
    "\n",
    "Función encargada de separar las filas que usaremos para el entrenamiento del modelo de las filas que usaremos para probar el modelo.  \n",
    "\n",
    "Se recibe el `DataFrame`, y el tamaño de la muestra de entrenamiento. Seguido creamos una variable `sample_df` que almacena una muestra de `df` pero organizado de forma aleatoria por el método `df.sample(frac = 1)` .  \n",
    "\n",
    "> **NOTA:** El método `sample()` se encarga de crear y retornar un `DataFrame` muestra, donde las filas han sido organizadas aleatoriamente. El *keyarg* `frac` representa el porcentaje de `df` que servirá como muestra. En esta ocasión está igualado a $1$ ya que necesitamos todo el `DataFrame`.\n",
    "\n",
    "Almacenamos los valores desde $0$ hasta `train_size-1` de esta muestra en la variable `train`. El resto es almacenado en la variable `test`.  \n",
    "\n",
    "Se retorna un `tuple` con ambos `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, train_size):\n",
    "    sample_df = df.sample(frac=1)\n",
    "    train     = sample_df[ : train_size]\n",
    "    test      = sample_df[train_size : ]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### euclidean_distance(p, q)\n",
    "\n",
    "Función encargada de calcular la distancia euclidiana entre la fila test $p$ y la fila train $q$.  \n",
    "\n",
    "Se reciben dos `numpy arrays` y se excluye el último valor de ambos, el cual representa el valor de `play`.\n",
    "Dado que son `numpy array` los arreglos pueden ser tratados como vectores euclidianos, por lo que hacemos la sustracción, y la elevación al cuadrado de forma directa. \n",
    "\n",
    "Esta operación retorna un nuevo `numpy array`, el cual es pasado como parámetro a la función `np.sum()`. `np.sum()` retorna la suma de todos los valores que se encuentran dentro de el *array*. El resultado de esta suma es pasado a la función `np.sqrt()` para calcular su raíz cuadrada.  \n",
    "\n",
    "Finalmente, el valor de la raíz cuadrada es retornado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p, q):\n",
    "    x = np.array(p.values)\n",
    "    y = np.array(q.values)[:-1]\n",
    "    return np.sqrt(np.sum((y - x) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### kNearestNeighbors(x, train_data, k)\n",
    "\n",
    "Función encargada de retornar los vecinos más cercanos a $p$.  \n",
    "\n",
    "Se recibe los siguientes argumentos:\n",
    "- `p` : Un `numpy array` que contiene la información de la fila a evaluar \n",
    "- `k` : El número de vecinos a tomar en cuenta \n",
    "- `train_data` : Un `DataFrame` con las filas de entrenamiento.  \n",
    "  \n",
    "Se crea un arreglo `neighbors` usando un técnica llamada *list comprehension*. El tamaño del arreglo es igual al tamaño de `train_data`.   \n",
    "Esta variable almacena un arreglo de *tuples*, los cuales tienen como primer elemento la distancia entre $p$ y $q_i$. El segundo elemento de cada `tuple` es el índice de $q_i$.  \n",
    "\n",
    "El arreglo se organiza de forma ascendente basándose en los valores de las distancias euclidianas y finalmente se retornan los primeros $k$ elementos del arreglo, los cuales representan los $k$ vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNearestNeighbors(p, train_data, k):\n",
    "    neighbors = [(euclidean_distance(p, q), i) for i, q in train_data.iterrows()]    \n",
    "    neighbors.sort()\n",
    "    return neighbors[ :k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train(k, train_data, test_data)\n",
    "\n",
    "Función encargada de predecir el valor de `play` de cada una de las filas en `test_data`, y retornar el porcentaje de error del modelo.  \n",
    "\n",
    "Recibe los siguientes parámetros:\n",
    "- `k` : Número de vecinos a tomar en cuenta\n",
    "- `train_data` : Un `DataFrame` con las filas de entrenamiento.\n",
    "- `test_data` : Un `DataFrame` con las filas de prueba.  \n",
    "\n",
    "Se inicializa una variable `errors` con un valor de $0$ que representa el número de resultados erróneos. Se aumenta en uno cada que la predicción sea distinta al valor de `p['play']`.  \n",
    "Una vez terminadas las predicciones, se retorna el porcentaje de errores en el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterations(k, df):\n",
    "    iterations = 20\n",
    "    good_guess = 0\n",
    "    for it in range(iterations):    \n",
    "        train_data, test_data = split_data(df, 10)\n",
    "        test_classes = test_data['play']\n",
    "        test_data = test_data.drop(['play'], axis=1)\n",
    "        \n",
    "        for i, p in test_data.iterrows():\n",
    "            y          = kNearestNeighbors(p, train_data, k)\n",
    "            results    = train_data.loc[[tup[1] for tup in y]]['play'].tolist()\n",
    "            prediction = stats.mode(results)\n",
    "\n",
    "            good_guess += 1 if prediction == test_classes.loc[i] else 0\n",
    "\n",
    "    return good_guess / (len(test_data) * iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path):\n",
    "    df = read_data(path)\n",
    "    model_results = [(iterations(k, df), k) for k in range(3, 8, 2)]\n",
    "    best_k        = max(model_results)\n",
    "    return best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelos: [(0.5625, 3), (0.5625, 5), (0.575, 7)]\n",
      "mejor k: 7\n"
     ]
    }
   ],
   "source": [
    "def predict(test_path, train_path, k):\n",
    "    test_df  = read_data(test_path)\n",
    "    train_df = read_data(train_path)\n",
    "    predictions = np.array([None] * len(test_df))\n",
    "\n",
    "    for i, p in test_df.iterrows():\n",
    "        y          = kNearestNeighbors(p, train_df, k)\n",
    "        results    = train_df.loc[[tup[1] for tup in y]]['play'].tolist()\n",
    "        prediction = stats.mode(results)\n",
    "        predictions[i] = prediction\n",
    "\n",
    "    test_df['play'] = predictions\n",
    "    test_df.to_csv('Tarea 1\\\\results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
